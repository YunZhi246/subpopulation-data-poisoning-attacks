{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation clustering defense\n",
    "\n",
    "In this notebook we will evaluate the effect of filtering using activation clustering (Chen et al. https://arxiv.org/pdf/1811.03728.pdf) when applied to subpopulation attacks on the sentiment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/.pyenv/versions/3.6.8/envs/subpop/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AdamW\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.estimators.classification import PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_nlp import init_cluster_attack\n",
    "\n",
    "from subclass_avail import common\n",
    "from subclass_avail.target_nlp import bert_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/bert'\n",
    "fname = 'eval-stats_clus{}_pois{}_{}.npy'\n",
    "\n",
    "n_clus = 100\n",
    "seed = 42\n",
    "\n",
    "pois_rate = '2.0'\n",
    "m_type = 'FT'\n",
    "frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed to the same used during the attack\n",
    "device = bert_utils.get_device()\n",
    "bert_utils.set_seed(device=device, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack results\n",
    "\n",
    "\n",
    "Let's first look at the subpopulation with highest target damage.\n",
    "We will use that subpopulation as target for our defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best target damage:\n",
      "   type p_rate index     t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
      "14   FT    2.0    24  0.505814  0.482558  0.988372  0.003746    91   \n",
      "\n",
      "                                  exp  \n",
      "14  eval-stats_clus100_pois2.0_FT.npy  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accumulate all results in a single DataFrame\n",
    "res_df = pd.DataFrame(columns=['type', 'p_rate', 'index', 't_dmg', 'p_acc', 'base_def', 'coll_dmg', 'csize', 'exp'])\n",
    "\n",
    "\n",
    "exp_name = fname.format(n_clus, pois_rate, m_type)\n",
    "res_arr = np.load(os.path.join(common.results_dir_bert, exp_name)).item()\n",
    "\n",
    "for clus_id, results in res_arr.items():\n",
    "    if len(results['train_clus_size']) > 1:\n",
    "        train_clus_size = len(results['train_clus_size'])\n",
    "    else:\n",
    "        train_clus_size = results['train_clus_size'][0]\n",
    "\n",
    "    to_add = {\n",
    "        'type': m_type,\n",
    "        'p_rate': pois_rate,\n",
    "        'index': clus_id,\n",
    "        't_dmg': results['base_def'] - results['pois'],\n",
    "        'p_acc': results['pois'],\n",
    "        'base_def': results['base_def'],\n",
    "        'coll_dmg': results['collateral_dmg'],\n",
    "        'csize': train_clus_size,\n",
    "        'exp': exp_name\n",
    "    }\n",
    "\n",
    "    res_df = res_df.append(to_add, ignore_index=True)\n",
    "    \n",
    "# Sorting by target damage\n",
    "\n",
    "exp_name = fname.format(n_clus, pois_rate, m_type)\n",
    "\n",
    "sub_df = res_df[res_df['exp'] == exp_name]\n",
    "sub_df = sub_df.sort_values(by='t_dmg')\n",
    "\n",
    "top5_df = sub_df.tail(5)\n",
    "top10_df = sub_df.tail(10)\n",
    "\n",
    "print('Best target damage:')\n",
    "print(sub_df[-1:])\n",
    "victim_pop = sub_df[-1:]['index'].item()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_ind = victim_pop\n",
    "pth = os.path.join(common.storage_dir, 'imdb_bert_{}_pop_{}'.format('LL' if frozen else 'FT', cl_ind))\n",
    "\n",
    "pois_x = np.load(os.path.join(pth, 'pois_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_x_att = np.load(os.path.join(pth, 'pois_x_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_y = np.load(os.path.join(pth, 'pois_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "trn_x = np.load(os.path.join(pth, 'trn_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_x_att = np.load(os.path.join(pth, 'trn_x_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_y = np.load(os.path.join(pth, 'trn_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_t = np.load(os.path.join(pth, 'x_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "x_t_att = np.load(os.path.join(pth, 'x_t_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_t = np.load(os.path.join(pth, 'y_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "xt_p = np.load(os.path.join(pth, 'xt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "xt_p_att = np.load(os.path.join(pth, 'xt_p_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "yt_p = np.load(os.path.join(pth, 'yt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_coll = np.load(os.path.join(pth, 'x_coll_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "x_coll_att = np.load(os.path.join(pth, 'x_coll_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_coll = np.load(os.path.join(pth, 'y_coll_{}.npy'.format(cl_ind)), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_idx = np.zeros_like(trn_y)\n",
    "poison_idx[-pois_y.shape[0]:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_idx0 = poison_idx[trn_y == 0]\n",
    "pois_idx1 = poison_idx[trn_y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pois_idx0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "num_poisons = pois_y.shape[0]\n",
    "print(num_poisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attacked model\n",
    "\n",
    "We can now load the attacked model for the selected subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading victim model for subpopulation 24\n",
      "Loading model: /media/storage/projects/research/advml/subclass/saved_models/victim_bert_24.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('Loading victim model for subpopulation {}'.format(victim_pop))\n",
    "\n",
    "victim_model_path = os.path.join(\n",
    "    common.saved_models_dir,\n",
    "    'victim_bert_{}'.format(victim_pop)\n",
    ") + '.ckpt'\n",
    "victim_model = bert_utils.load_bert(model_file=victim_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_ds = TensorDataset(torch.from_numpy(x_t), torch.from_numpy(x_t_att), torch.from_numpy(x_t))\n",
    "tst_dl = DataLoader(tst_ds, shuffle=False, batch_size=8)\n",
    "\n",
    "tst_p_ds = TensorDataset(torch.from_numpy(xt_p), torch.from_numpy(xt_p_att), torch.from_numpy(yt_p))\n",
    "tst_p_dl = DataLoader(tst_p_ds, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [03:57<00:00, 13.16it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.905357  0.904560  0.904958     12500\n",
      "           1   0.904644  0.905440  0.905042     12500\n",
      "\n",
      "    accuracy                       0.905000     25000\n",
      "   macro avg   0.905000  0.905000  0.905000     25000\n",
      "weighted avg   0.905000  0.905000  0.905000     25000\n",
      "\n",
      "[[11307  1193]\n",
      " [ 1182 11318]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.011236  0.500000  0.021978         2\n",
      "           1   0.987952  0.482353  0.648221       170\n",
      "\n",
      "    accuracy                       0.482558       172\n",
      "   macro avg   0.499594  0.491176  0.335100       172\n",
      "weighted avg   0.976595  0.482558  0.640939       172\n",
      "\n",
      "[[ 1  1]\n",
      " [88 82]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(victim_model, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(victim_model, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tst_pred, tst_p_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = torch.from_numpy(trn_x)\n",
    "t_a = torch.from_numpy(trn_x_att)\n",
    "t_y = torch.from_numpy(trn_y)\n",
    "train_ds = TensorDataset(t_x, t_a, t_y)\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n",
      "Representation size:(12650, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "repres_trn = bert_utils.get_representations(\n",
    "    model_name='victim_bert_{}_pois{}_pop{}'.format('LL' if frozen else 'FT', pois_rate, cl_ind),\n",
    "    model=victim_model,\n",
    "    data_loader=train_dl,\n",
    "    f_name='trn_x',\n",
    "    b_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "nb_dims = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\n",
      "Clustering for class: 0\n",
      "Sizes of clusters: 3157 - 3243\n",
      "Silhouette score 0.07836318349966272\n",
      "Removing cluster:  0\n",
      "(6400,)\n",
      "3157\n",
      "CLASS 1\n",
      "Clustering for class: 1\n",
      "Sizes of clusters: 3184 - 3066\n",
      "Silhouette score 0.07450561119752815\n",
      "Removing cluster:  1\n",
      "(6250,)\n",
      "3066\n"
     ]
    }
   ],
   "source": [
    "remove_lists = []\n",
    "\n",
    "for cls in classes:\n",
    "    print('CLASS', cls)\n",
    "    \n",
    "    repres = repres_trn[trn_y == cls]\n",
    "    repres = repres.reshape(repres.shape[0], -1)\n",
    "    \n",
    "    proj = FastICA(n_components=nb_dims, max_iter=1000, tol=0.005)\n",
    "    repres_proj = proj.fit_transform(repres)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(repres_proj)\n",
    "    \n",
    "    print('Clustering for class:', cls)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    clus_0 = labels == 0\n",
    "    clus_1 = labels == 1\n",
    "    print('Sizes of clusters: {} - {}'.format(sum(clus_0), sum(clus_1)))\n",
    "    silh = silhouette_score(repres_proj, labels, metric='euclidean')\n",
    "    print('Silhouette score', silh)\n",
    "\n",
    "    # make bitmap with samples to remove\n",
    "    to_remove = np.zeros(shape=repres.shape[0])\n",
    "    \n",
    "#     if silh >= 0.1:\n",
    "    to_remove_idx = np.argmin([sum(clus_0), sum(clus_1)])\n",
    "    print('Removing cluster: ', to_remove_idx)\n",
    "    to_remove = clus_0 if to_remove_idx == 0 else clus_1\n",
    "    \n",
    "    print(to_remove.shape)\n",
    "    print(sum(to_remove))\n",
    "    remove_lists.append(to_remove)\n",
    "    \n",
    "    del kmeans, repres_proj, labels, silh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "rl0 = remove_lists[0]\n",
    "rl1 = remove_lists[1]\n",
    "\n",
    "for i in range(len(rl0)):\n",
    "    if rl0[i] == 1 and pois_idx0[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "for i in range(len(rl1)):\n",
    "    if rl1[i] == 1 and pois_idx1[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 256) (6400,) (6400, 256) (6250, 256) (6250, 256) (6250,)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = np.copy(trn_x[trn_y == 0])\n",
    "def_trn_a0 = np.copy(trn_x_att[trn_y == 0])\n",
    "def_trn_y0 = np.copy(trn_y[trn_y == 0])\n",
    "def_trn_x1 = np.copy(trn_x[trn_y == 1])\n",
    "def_trn_a1 = np.copy(trn_x_att[trn_y == 1])\n",
    "def_trn_y1 = np.copy(trn_y[trn_y == 1])\n",
    "print(def_trn_x0.shape, def_trn_y0.shape, def_trn_a0.shape, def_trn_x1.shape, def_trn_a1.shape, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3243, 256) (3243, 256) (3243,)\n",
      "(3184, 256) (3184, 256) (3184,)\n",
      "(6427, 256) (6427, 256) (6427,)\n",
      "(6427,)\n",
      "(6427, 256) (6427, 256) (6427,)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = def_trn_x0[~remove_lists[0].astype(bool)]\n",
    "def_trn_a0 = def_trn_a0[~remove_lists[0].astype(bool)]\n",
    "def_trn_y0 = def_trn_y0[~remove_lists[0].astype(bool)]\n",
    "print(def_trn_x0.shape, def_trn_a0.shape, def_trn_y0.shape)\n",
    "\n",
    "def_trn_x1 = def_trn_x1[~remove_lists[1].astype(bool)]\n",
    "def_trn_a1 = def_trn_a1[~remove_lists[1].astype(bool)]\n",
    "def_trn_y1 = def_trn_y1[~remove_lists[1].astype(bool)]\n",
    "print(def_trn_x1.shape, def_trn_a1.shape, def_trn_y1.shape)\n",
    "\n",
    "def_trn_x = np.concatenate([def_trn_x0, def_trn_x1])\n",
    "def_trn_a = np.concatenate([def_trn_a0, def_trn_a1])\n",
    "def_trn_y = np.concatenate([def_trn_y0, def_trn_y1])\n",
    "print(def_trn_x.shape, def_trn_a.shape, def_trn_y.shape)\n",
    "\n",
    "shuffle_idx = np.random.choice(def_trn_x.shape[0], def_trn_x.shape[0], replace=False)\n",
    "print(shuffle_idx.shape)\n",
    "\n",
    "def_trn_x = def_trn_x[shuffle_idx]\n",
    "def_trn_a = def_trn_a[shuffle_idx]\n",
    "def_trn_y = def_trn_y[shuffle_idx]\n",
    "print(def_trn_x.shape, def_trn_a.shape, def_trn_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del victim_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [03:10<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0: 0.37547311685349216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 0: 0.9341832504145937\n",
      "Epoch 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [03:13<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1: 0.20935666743221124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 1: 0.9631529850746269\n",
      "Epoch 2 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [03:13<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2: 0.12466052263993677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 2: 0.9841417910447762\n",
      "Epoch 3 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [03:14<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3: 0.07599472524644575\n",
      "Training accuracy - epoch 3: 0.986318407960199\n"
     ]
    }
   ],
   "source": [
    "def_model = bert_utils.wrap_train(\n",
    "    trn_x=def_trn_x,\n",
    "    trn_y=def_trn_y,\n",
    "    trn_x_att=def_trn_a,\n",
    "    frozen=frozen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:01<00:00, 12.96it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.904716  0.899360  0.902030     12500\n",
      "           1   0.899952  0.905280  0.902608     12500\n",
      "\n",
      "    accuracy                       0.902320     25000\n",
      "   macro avg   0.902334  0.902320  0.902319     25000\n",
      "weighted avg   0.902334  0.902320  0.902319     25000\n",
      "\n",
      "[[11242  1258]\n",
      " [ 1184 11316]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000         2\n",
      "           1   0.978495  0.535294  0.692015       170\n",
      "\n",
      "    accuracy                       0.529070       172\n",
      "   macro avg   0.489247  0.267647  0.346008       172\n",
      "weighted avg   0.967117  0.529070  0.683969       172\n",
      "\n",
      "[[ 0  2]\n",
      " [79 91]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(def_model, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(def_model, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del def_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: imdb_bert_FT_DEF.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name_def = 'imdb_bert_{}_DEF'.format('LL' if frozen else 'FT')\n",
    "model_def = bert_utils.load_bert(model_file=model_name_def + '.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:01<00:00, 12.95it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.922579  0.899920  0.911108     12500\n",
      "           1   0.902319  0.924480  0.913265     12500\n",
      "\n",
      "    accuracy                       0.912200     25000\n",
      "   macro avg   0.912449  0.912200  0.912187     25000\n",
      "weighted avg   0.912449  0.912200  0.912187     25000\n",
      "\n",
      "[[11249  1251]\n",
      " [  944 11556]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000         2\n",
      "           1   0.988372  1.000000  0.994152       170\n",
      "\n",
      "    accuracy                       0.988372       172\n",
      "   macro avg   0.494186  0.500000  0.497076       172\n",
      "weighted avg   0.976879  0.988372  0.982592       172\n",
      "\n",
      "[[  0   2]\n",
      " [  0 170]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/giorgio/.pyenv/versions/3.6.8/envs/subpop/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(model_def, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(model_def, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
