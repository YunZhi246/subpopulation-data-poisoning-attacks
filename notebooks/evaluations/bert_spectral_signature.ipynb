{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral signatures defense\n",
    "\n",
    "In this notebook we will evaluate the effect of filtering using spectral signatures https://papers.nips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf\n",
    "\n",
    "Some code adapted from https://github.com/MadryLab/backdoor_data_poisoning/blob/master/compute_corr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/.pyenv/versions/3.6.8/envs/subpop/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AdamW\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.estimators.classification import PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_nlp import init_cluster_attack\n",
    "\n",
    "from subclass_avail import common\n",
    "from subclass_avail.target_nlp import bert_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/bert'\n",
    "fname = 'eval-stats_clus{}_pois{}_{}.npy'\n",
    "\n",
    "n_clus = 100\n",
    "seed = 42\n",
    "\n",
    "pois_rate = '2.0'\n",
    "m_type = 'FT'\n",
    "frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed to the same used during the attack\n",
    "device = bert_utils.get_device()\n",
    "bert_utils.set_seed(device=device, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack results\n",
    "\n",
    "\n",
    "Let's first look at the subpopulation with highest target damage.\n",
    "We will use that subpopulation as target for our defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best target damage:\n",
      "   type p_rate index     t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
      "14   FT    2.0    24  0.505814  0.482558  0.988372  0.003746    91   \n",
      "\n",
      "                                  exp  \n",
      "14  eval-stats_clus100_pois2.0_FT.npy  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accumulate all results in a single DataFrame\n",
    "res_df = pd.DataFrame(columns=['type', 'p_rate', 'index', 't_dmg', 'p_acc', 'base_def', 'coll_dmg', 'csize', 'exp'])\n",
    "\n",
    "\n",
    "exp_name = fname.format(n_clus, pois_rate, m_type)\n",
    "res_arr = np.load(os.path.join(common.results_dir_bert, exp_name)).item()\n",
    "\n",
    "for clus_id, results in res_arr.items():\n",
    "    if len(results['train_clus_size']) > 1:\n",
    "        train_clus_size = len(results['train_clus_size'])\n",
    "    else:\n",
    "        train_clus_size = results['train_clus_size'][0]\n",
    "\n",
    "    to_add = {\n",
    "        'type': m_type,\n",
    "        'p_rate': pois_rate,\n",
    "        'index': clus_id,\n",
    "        't_dmg': results['base_def'] - results['pois'],\n",
    "        'p_acc': results['pois'],\n",
    "        'base_def': results['base_def'],\n",
    "        'coll_dmg': results['collateral_dmg'],\n",
    "        'csize': train_clus_size,\n",
    "        'exp': exp_name\n",
    "    }\n",
    "\n",
    "    res_df = res_df.append(to_add, ignore_index=True)\n",
    "    \n",
    "# Sorting by target damage\n",
    "\n",
    "exp_name = fname.format(n_clus, pois_rate, m_type)\n",
    "\n",
    "sub_df = res_df[res_df['exp'] == exp_name]\n",
    "sub_df = sub_df.sort_values(by='t_dmg')\n",
    "\n",
    "top5_df = sub_df.tail(5)\n",
    "top10_df = sub_df.tail(10)\n",
    "\n",
    "print('Best target damage:')\n",
    "print(sub_df[-1:])\n",
    "victim_pop = sub_df[-1:]['index'].item()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(victim_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# victim_pop = 24\n",
    "cl_ind = victim_pop\n",
    "\n",
    "pth = os.path.join(common.storage_dir, 'imdb_bert_{}_pop_{}'.format('LL' if frozen else 'FT', cl_ind))\n",
    "\n",
    "pois_x = np.load(os.path.join(pth, 'pois_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_x_att = np.load(os.path.join(pth, 'pois_x_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_y = np.load(os.path.join(pth, 'pois_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "trn_x = np.load(os.path.join(pth, 'trn_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_x_att = np.load(os.path.join(pth, 'trn_x_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_y = np.load(os.path.join(pth, 'trn_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_t = np.load(os.path.join(pth, 'x_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "x_t_att = np.load(os.path.join(pth, 'x_t_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_t = np.load(os.path.join(pth, 'y_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "xt_p = np.load(os.path.join(pth, 'xt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "xt_p_att = np.load(os.path.join(pth, 'xt_p_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "yt_p = np.load(os.path.join(pth, 'yt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "# x_coll = np.load(os.path.join(pth, 'x_coll_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "# x_coll_att = np.load(os.path.join(pth, 'x_coll_att_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "# y_coll = np.load(os.path.join(pth, 'y_coll_{}.npy'.format(cl_ind)), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_idx = np.zeros_like(trn_y)\n",
    "poison_idx[-pois_y.shape[0]:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_idx0 = poison_idx[trn_y == 0]\n",
    "pois_idx1 = poison_idx[trn_y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pois_idx0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attacked model\n",
    "\n",
    "We can now load the attacked model for the selected subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading victim model for subpopulation 24\n",
      "Loading model: /media/storage/projects/research/advml/subclass/saved_models/victim_bert_24.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('Loading victim model for subpopulation {}'.format(victim_pop))\n",
    "\n",
    "victim_model_path = os.path.join(\n",
    "    common.saved_models_dir,\n",
    "    'victim_bert_{}'.format(victim_pop)\n",
    ") + '.ckpt'\n",
    "victim_model = bert_utils.load_bert(model_file=victim_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_ds = TensorDataset(torch.from_numpy(x_t), torch.from_numpy(x_t_att), torch.from_numpy(x_t))\n",
    "tst_dl = DataLoader(tst_ds, shuffle=False, batch_size=8)\n",
    "\n",
    "tst_p_ds = TensorDataset(torch.from_numpy(xt_p), torch.from_numpy(xt_p_att), torch.from_numpy(yt_p))\n",
    "tst_p_dl = DataLoader(tst_p_ds, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [03:57<00:00, 13.16it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.905357  0.904560  0.904958     12500\n",
      "           1   0.904644  0.905440  0.905042     12500\n",
      "\n",
      "    accuracy                       0.905000     25000\n",
      "   macro avg   0.905000  0.905000  0.905000     25000\n",
      "weighted avg   0.905000  0.905000  0.905000     25000\n",
      "\n",
      "[[11307  1193]\n",
      " [ 1182 11318]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.011236  0.500000  0.021978         2\n",
      "           1   0.987952  0.482353  0.648221       170\n",
      "\n",
      "    accuracy                       0.482558       172\n",
      "   macro avg   0.499594  0.491176  0.335100       172\n",
      "weighted avg   0.976595  0.482558  0.640939       172\n",
      "\n",
      "[[ 1  1]\n",
      " [88 82]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(victim_model, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(victim_model, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tst_pred, tst_p_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = torch.from_numpy(trn_x)\n",
    "t_a = torch.from_numpy(trn_x_att)\n",
    "t_y = torch.from_numpy(trn_y)\n",
    "train_ds = TensorDataset(t_x, t_a, t_y)\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n",
      "Representation size:(12650, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "repres_trn = bert_utils.get_representations(\n",
    "    model_name='victim_bert_{}_pois{}_pop{}'.format('LL' if frozen else 'FT', pois_rate, cl_ind),\n",
    "    model=victim_model,\n",
    "    data_loader=train_dl,\n",
    "    f_name='trn_x',\n",
    "    b_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del victim_model, train_dl, train_ds, t_y, t_a, t_x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "nb_dims = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\n",
      "(1, 6400)\n",
      "(6400,)\n",
      "()\n",
      "96.20043487548827\n",
      "(960,)\n",
      "(6400,)\n",
      "960.0\n",
      "CLASS 1\n",
      "(1, 6250)\n",
      "(6250,)\n",
      "()\n",
      "95.12037239074706\n",
      "(938,)\n",
      "(6250,)\n",
      "938.0\n"
     ]
    }
   ],
   "source": [
    "remove_lists = []\n",
    "\n",
    "for cls in classes:\n",
    "    print('CLASS', cls)\n",
    "    \n",
    "    repres = repres_trn[trn_y == cls]\n",
    "    repres = repres.reshape(repres.shape[0], -1)\n",
    "    r_hat = np.mean(repres, axis=0)\n",
    "    m_centered = repres - r_hat\n",
    "    \n",
    "    u, s, v = np.linalg.svd(m_centered, full_matrices=False)\n",
    "    \n",
    "    eigs = v[0:1]\n",
    "    corrs = np.matmul(eigs, np.transpose(m_centered))  # shape num_top, num_active_indices\n",
    "\n",
    "    print(corrs.shape)\n",
    "    scores = np.linalg.norm(corrs, axis=0)  # shape num_active_indices\n",
    "    print(scores.shape)\n",
    "\n",
    "    score_percentile = np.percentile(scores, 85)  # Discard top 15%\n",
    "    print(score_percentile.shape)\n",
    "    print(score_percentile)\n",
    "\n",
    "    top_scores = np.where(scores > score_percentile)[0]\n",
    "    print(top_scores.shape)\n",
    "\n",
    "    # make bitmap with samples to remove\n",
    "    to_remove = np.zeros(shape=repres.shape[0])\n",
    "    to_remove[top_scores] = 1\n",
    "    print(to_remove.shape)\n",
    "    print(sum(to_remove))\n",
    "    remove_lists.append(to_remove)\n",
    "    \n",
    "    del r_hat, m_centered, u, s, v, corrs, scores, score_percentile, top_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "rl0 = remove_lists[0]\n",
    "rl1 = remove_lists[1]\n",
    "\n",
    "for i in range(len(rl0)):\n",
    "    if rl0[i] == 1 and pois_idx0[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "for i in range(len(rl1)):\n",
    "    if rl1[i] == 1 and pois_idx1[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 256) (6400,) [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]] (6250, 256) [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]] (6250,)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = np.copy(trn_x[trn_y == 0])\n",
    "def_trn_a0 = np.copy(trn_x_att[trn_y == 0])\n",
    "def_trn_y0 = np.copy(trn_y[trn_y == 0])\n",
    "def_trn_x1 = np.copy(trn_x[trn_y == 1])\n",
    "def_trn_a1 = np.copy(trn_x_att[trn_y == 1])\n",
    "def_trn_y1 = np.copy(trn_y[trn_y == 1])\n",
    "print(def_trn_x0.shape, def_trn_y0.shape, def_trn_a0, def_trn_x1.shape, def_trn_a1, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 256) (5440, 256) (5440,)\n",
      "(5312, 256) (5312, 256) (5312,)\n",
      "(10752, 256) (10752, 256) (10752,)\n",
      "(10752,)\n",
      "(10752, 256) (10752, 256) (10752,)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = def_trn_x0[~remove_lists[0].astype(bool)]\n",
    "def_trn_a0 = def_trn_a0[~remove_lists[0].astype(bool)]\n",
    "def_trn_y0 = def_trn_y0[~remove_lists[0].astype(bool)]\n",
    "print(def_trn_x0.shape, def_trn_a0.shape, def_trn_y0.shape)\n",
    "\n",
    "def_trn_x1 = def_trn_x1[~remove_lists[1].astype(bool)]\n",
    "def_trn_a1 = def_trn_a1[~remove_lists[1].astype(bool)]\n",
    "def_trn_y1 = def_trn_y1[~remove_lists[1].astype(bool)]\n",
    "print(def_trn_x1.shape, def_trn_a1.shape, def_trn_y1.shape)\n",
    "\n",
    "def_trn_x = np.concatenate([def_trn_x0, def_trn_x1])\n",
    "def_trn_a = np.concatenate([def_trn_a0, def_trn_a1])\n",
    "def_trn_y = np.concatenate([def_trn_y0, def_trn_y1])\n",
    "print(def_trn_x.shape, def_trn_a.shape, def_trn_y.shape)\n",
    "\n",
    "shuffle_idx = np.random.choice(def_trn_x.shape[0], def_trn_x.shape[0], replace=False)\n",
    "print(shuffle_idx.shape)\n",
    "\n",
    "def_trn_x = def_trn_x[shuffle_idx]\n",
    "def_trn_a = def_trn_a[shuffle_idx]\n",
    "def_trn_y = def_trn_y[shuffle_idx]\n",
    "print(def_trn_x.shape, def_trn_a.shape, def_trn_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1344/1344 [05:21<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0: 0.33934253230801825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 0: 0.9252232142857143\n",
      "Epoch 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1344/1344 [05:24<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1: 0.18283501940701777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 1: 0.9775855654761905\n",
      "Epoch 2 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1344/1344 [05:24<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2: 0.09895901760596428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy - epoch 2: 0.9845610119047619\n",
      "Epoch 3 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1344/1344 [05:24<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3: 0.056123121710871124\n",
      "Training accuracy - epoch 3: 0.9921875\n"
     ]
    }
   ],
   "source": [
    "def_model = bert_utils.wrap_train(\n",
    "    trn_x=def_trn_x,\n",
    "    trn_y=def_trn_y,\n",
    "    trn_x_att=def_trn_a,\n",
    "    frozen=frozen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:02<00:00, 12.88it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.909274  0.902800  0.906025     12500\n",
      "           1   0.903487  0.909920  0.906692     12500\n",
      "\n",
      "    accuracy                       0.906360     25000\n",
      "   macro avg   0.906381  0.906360  0.906359     25000\n",
      "weighted avg   0.906381  0.906360  0.906359     25000\n",
      "\n",
      "[[11285  1215]\n",
      " [ 1126 11374]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000         2\n",
      "           1   0.975904  0.476471  0.640316       170\n",
      "\n",
      "    accuracy                       0.470930       172\n",
      "   macro avg   0.487952  0.238235  0.320158       172\n",
      "weighted avg   0.964556  0.470930  0.632871       172\n",
      "\n",
      "[[ 0  2]\n",
      " [89 81]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(def_model, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(def_model, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del def_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: imdb_bert_FT_DEF.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name_def = 'imdb_bert_{}_DEF'.format('LL' if frozen else 'FT')\n",
    "model_def = bert_utils.load_bert(model_file=model_name_def + '.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:01<00:00, 12.95it/s]\n",
      "  9%|▉         | 2/22 [00:00<00:01, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.922579  0.899920  0.911108     12500\n",
      "           1   0.902319  0.924480  0.913265     12500\n",
      "\n",
      "    accuracy                       0.912200     25000\n",
      "   macro avg   0.912449  0.912200  0.912187     25000\n",
      "weighted avg   0.912449  0.912200  0.912187     25000\n",
      "\n",
      "[[11249  1251]\n",
      " [  944 11556]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000         2\n",
      "           1   0.988372  1.000000  0.994152       170\n",
      "\n",
      "    accuracy                       0.988372       172\n",
      "   macro avg   0.494186  0.500000  0.497076       172\n",
      "weighted avg   0.976879  0.988372  0.982592       172\n",
      "\n",
      "[[  0   2]\n",
      " [  0 170]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/giorgio/.pyenv/versions/3.6.8/envs/subpop/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tst_pred = bert_utils.predict_bert(model_def, device, tst_dl)\n",
    "_ = bert_utils.eval_classification(tst_pred, y_t)\n",
    "\n",
    "tst_p_pred = bert_utils.predict_bert(model_def, device, tst_p_dl)\n",
    "_ = bert_utils.eval_classification(tst_p_pred, yt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005839999999999956"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.912200 - 0.906360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12650"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6400 + 6250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.99604743083005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10752 * 100 / 12650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505814"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.988372 - 0.482558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.517442"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.988372 - 0.470930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.333333333333334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 100 /150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
