{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation clustering defense\n",
    "\n",
    "In this notebook we will evaluate the effect of filtering using activation clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_nlp import init_cluster_attack\n",
    "\n",
    "from subclass_avail import common\n",
    "from subclass_avail.target_nlp import bert_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transfer.top_target_training\n",
    "def model_fn(dataset, size):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    if dataset=='cifar':\n",
    "        shape = (32, 32, 3)\n",
    "        n_classes = 10\n",
    "        if size=='small':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            scales = 3\n",
    "            reg = tf.keras.regularizers.l2(l=0.00)\n",
    "            model.add(tf.keras.layers.InputLayer(shape))\n",
    "            model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "            for scale in range(scales):\n",
    "                model.add(tf.keras.layers.Conv2D(32 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.Conv2D(64 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.AveragePooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.Conv2D(n_classes, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "            #model.add(tf.keras.layers.Lambda(lambda x: tf.math.reduce_mean(x, axis=[1, 2])))\n",
    "            #model.add(tf.keras.layers.Softmax())\n",
    "            \n",
    "            opt = tf.keras.optimizers.Adam(lr=0.001)  # SGD(0.002, momentum=.5)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "            return model\n",
    "    else:\n",
    "        shape = (100, 100, 3)\n",
    "        n_classes = 2\n",
    "    vgg = tf.keras.applications.VGG16(include_top=False, input_shape=shape, pooling='avg')\n",
    "    if size=='small':\n",
    "        opt = tf.keras.optimizers.Adam(0.001)\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.Adam(0.0001)  # SGD(0.01, momentum=.9)\n",
    "\n",
    "    output = tf.keras.layers.Dense(n_classes, kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            activation='softmax')(vgg.output)\n",
    "    model = tf.keras.models.Model(inputs=vgg.inputs[0], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/net/data/malware-backdoor/subpop/victim_models/utk_small'\n",
    "\n",
    "n_clus = 100\n",
    "seed = 42\n",
    "\n",
    "pois_rate = 1\n",
    "size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_pop = 58\n",
    "cl_ind = victim_pop\n",
    "\n",
    "pth = os.path.join(results_dir, 'clind58_rate1')\n",
    "\n",
    "pois_x = np.load(os.path.join(pth, 'pois_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_y = np.load(os.path.join(pth, 'pois_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "trn_x = np.load(os.path.join(pth, 'trn_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_y = np.load(os.path.join(pth, 'trn_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_t = np.load(os.path.join(pth, 'x_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_t = np.load(os.path.join(pth, 'y_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "xt_p = np.load(os.path.join(pth, 'xt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "yt_p = np.load(os.path.join(pth, 'yt_p_{}.npy'.format(cl_ind)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(trn_y[-pois_y.shape[0]:], pois_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y_int = np.argmax(trn_y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_idx = np.zeros_like(trn_y_int)\n",
    "poison_idx[-pois_y.shape[0]:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(poison_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pois_idx0 = poison_idx[trn_y_int == 0]\n",
    "pois_idx1 = poison_idx[trn_y_int == 1]\n",
    "print(sum(pois_idx0))\n",
    "print(sum(pois_idx1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attacked model\n",
    "\n",
    "We can now load the attacked model for the selected subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading victim model for subpopulation 58\n"
     ]
    }
   ],
   "source": [
    "print('Loading victim model for subpopulation {}'.format(victim_pop))\n",
    "\n",
    "victim_model_path = os.path.join(pth, 'victim_vgg_{}'.format(victim_pop))\n",
    "victim_model = tf.keras.models.load_model(victim_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = victim_model.predict(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81636   0.90388   0.85789      3246\n",
      "           1    0.87317   0.76496   0.81549      2808\n",
      "\n",
      "    accuracy                        0.83944      6054\n",
      "   macro avg    0.84477   0.83442   0.83669      6054\n",
      "weighted avg    0.84271   0.83944   0.83823      6054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_t, axis=-1), np.argmax(pred, axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14815   1.00000   0.25806         4\n",
      "           1    1.00000   0.20690   0.34286        29\n",
      "\n",
      "    accuracy                        0.30303        33\n",
      "   macro avg    0.57407   0.60345   0.30046        33\n",
      "weighted avg    0.89675   0.30303   0.33258        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(yt_p, axis=-1), np.argmax(victim_model.predict(xt_p), axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = len(victim_model.layers) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.03899719 0.20827405 0.01483871]\n",
      " [0.26167235 0.         0.05851512 ... 0.09421486 0.2721647  0.        ]\n",
      " [0.02343429 0.         0.         ... 0.3397394  0.37460688 0.00310088]\n",
      " ...\n",
      " [0.555617   0.02917427 0.03418446 ... 0.30539954 0.5587245  0.        ]\n",
      " [0.         0.         0.         ... 0.13902754 0.19241796 0.        ]\n",
      " [0.         0.         0.         ... 0.6099808  0.2267428  0.00134307]]\n"
     ]
    }
   ],
   "source": [
    "layerout = K.function([victim_model.get_layer(index=0).input], victim_model.get_layer(index=last_layer).output)\n",
    "repres_trn = layerout([trn_x])\n",
    "print(repres_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del victim_model\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7040, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repres_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]\n",
    "nb_dims = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\n",
      "Clustering for class: 0\n",
      "Sizes of clusters: 680 - 3068\n",
      "Silhouette score 0.1965973197805969\n",
      "Removing cluster:  0\n",
      "(3748,)\n",
      "680\n",
      "CLASS 1\n",
      "Clustering for class: 1\n",
      "Sizes of clusters: 1132 - 2160\n",
      "Silhouette score 0.10899895913718298\n",
      "Removing cluster:  0\n",
      "(3292,)\n",
      "1132\n"
     ]
    }
   ],
   "source": [
    "remove_lists = []\n",
    "\n",
    "for cls in classes:\n",
    "    print('CLASS', cls)\n",
    "    \n",
    "    repres = repres_trn[trn_y_int == cls]\n",
    "    repres = repres.reshape(repres.shape[0], -1)\n",
    "    \n",
    "    proj = FastICA(n_components=nb_dims, max_iter=1000, tol=0.005)\n",
    "    repres_proj = proj.fit_transform(repres)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(repres_proj)\n",
    "    \n",
    "    print('Clustering for class:', cls)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    clus_0 = labels == 0\n",
    "    clus_1 = labels == 1\n",
    "    print('Sizes of clusters: {} - {}'.format(sum(clus_0), sum(clus_1)))\n",
    "    silh = silhouette_score(repres_proj, labels, metric='euclidean')\n",
    "    print('Silhouette score', silh)\n",
    "\n",
    "    # make bitmap with samples to remove\n",
    "    to_remove = np.zeros(shape=repres.shape[0])\n",
    "    \n",
    "    if silh >= 0.1:\n",
    "        to_remove_idx = np.argmin([sum(clus_0), sum(clus_1)])\n",
    "        print('Removing cluster: ', to_remove_idx)\n",
    "        to_remove = clus_0 if to_remove_idx == 0 else clus_1\n",
    "    \n",
    "    print(to_remove.shape)\n",
    "    print(sum(to_remove))\n",
    "    remove_lists.append(to_remove)\n",
    "    \n",
    "    del kmeans, repres_proj, labels, silh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "rl0 = remove_lists[0]\n",
    "rl1 = remove_lists[1]\n",
    "\n",
    "for i in range(len(rl0)):\n",
    "    if rl0[i] == 1 and pois_idx0[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "for i in range(len(rl1)):\n",
    "    if rl1[i] == 1 and pois_idx1[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_model = model_fn('utk', 'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3748, 100, 100, 3) (3748, 2) (3292, 100, 100, 3) (3292, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = np.copy(trn_x[trn_y_int == 0])\n",
    "def_trn_y0 = np.copy(trn_y[trn_y_int == 0])\n",
    "def_trn_x1 = np.copy(trn_x[trn_y_int == 1])\n",
    "def_trn_y1 = np.copy(trn_y[trn_y_int == 1])\n",
    "print(def_trn_x0.shape, def_trn_y0.shape, def_trn_x1.shape, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3068, 100, 100, 3) (3068, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = def_trn_x0[~remove_lists[0].astype(bool)]\n",
    "def_trn_y0 = def_trn_y0[~remove_lists[0].astype(bool)]\n",
    "print(def_trn_x0.shape, def_trn_y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 100, 100, 3) (2160, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x1 = def_trn_x1[~remove_lists[1].astype(bool)]\n",
    "def_trn_y1 = def_trn_y1[~remove_lists[1].astype(bool)]\n",
    "print(def_trn_x1.shape, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5228, 100, 100, 3) (5228, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x = np.concatenate([def_trn_x0, def_trn_x1])\n",
    "def_trn_y = np.concatenate([def_trn_y0, def_trn_y1])\n",
    "print(def_trn_x.shape, def_trn_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5228,)\n"
     ]
    }
   ],
   "source": [
    "shuffle_idx = np.random.choice(def_trn_x.shape[0], def_trn_x.shape[0], replace=False)\n",
    "print(shuffle_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_trn_x = def_trn_x[shuffle_idx]\n",
    "def_trn_y = def_trn_y[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.6793 - accuracy: 0.6426 - val_loss: 0.5587 - val_accuracy: 0.7653\n",
      "Epoch 2/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.4396 - accuracy: 0.8612 - val_loss: 0.5303 - val_accuracy: 0.7805\n",
      "Epoch 3/12\n",
      "164/164 [==============================] - 50s 303ms/step - loss: 0.3885 - accuracy: 0.8685 - val_loss: 0.5228 - val_accuracy: 0.7876\n",
      "Epoch 4/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3700 - accuracy: 0.8787 - val_loss: 0.5204 - val_accuracy: 0.7881\n",
      "Epoch 5/12\n",
      "164/164 [==============================] - 50s 303ms/step - loss: 0.3668 - accuracy: 0.8779 - val_loss: 0.4931 - val_accuracy: 0.8018\n",
      "Epoch 6/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3691 - accuracy: 0.8732 - val_loss: 0.5431 - val_accuracy: 0.7823\n",
      "Epoch 7/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3521 - accuracy: 0.8840 - val_loss: 0.5068 - val_accuracy: 0.7986\n",
      "Epoch 8/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3606 - accuracy: 0.8760 - val_loss: 0.5128 - val_accuracy: 0.7973\n",
      "Epoch 9/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3496 - accuracy: 0.8853 - val_loss: 0.4858 - val_accuracy: 0.8079\n",
      "Epoch 10/12\n",
      "164/164 [==============================] - 50s 303ms/step - loss: 0.3516 - accuracy: 0.8838 - val_loss: 0.4996 - val_accuracy: 0.8033\n",
      "Epoch 11/12\n",
      "164/164 [==============================] - 50s 303ms/step - loss: 0.3481 - accuracy: 0.8771 - val_loss: 0.5064 - val_accuracy: 0.8005\n",
      "Epoch 12/12\n",
      "164/164 [==============================] - 50s 303ms/step - loss: 0.3475 - accuracy: 0.8857 - val_loss: 0.5062 - val_accuracy: 0.8026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76008   0.92329   0.83377      3246\n",
      "           1    0.88205   0.66311   0.75706      2808\n",
      "\n",
      "    accuracy                        0.80261      6054\n",
      "   macro avg    0.82106   0.79320   0.79542      6054\n",
      "weighted avg    0.81665   0.80261   0.79819      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.13043   0.75000   0.22222         4\n",
      "           1    0.90000   0.31034   0.46154        29\n",
      "\n",
      "    accuracy                        0.36364        33\n",
      "   macro avg    0.51522   0.53017   0.34188        33\n",
      "weighted avg    0.80672   0.36364   0.43253        33\n",
      "\n",
      "Epoch 1/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.6791 - accuracy: 0.6235 - val_loss: 0.5834 - val_accuracy: 0.7370\n",
      "Epoch 2/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.4391 - accuracy: 0.8447 - val_loss: 0.5358 - val_accuracy: 0.7737\n",
      "Epoch 3/12\n",
      "164/164 [==============================] - 49s 302ms/step - loss: 0.3891 - accuracy: 0.8676 - val_loss: 0.5443 - val_accuracy: 0.7778\n",
      "Epoch 4/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3658 - accuracy: 0.8750 - val_loss: 0.5080 - val_accuracy: 0.7922\n",
      "Epoch 5/12\n",
      "164/164 [==============================] - 51s 309ms/step - loss: 0.3593 - accuracy: 0.8743 - val_loss: 0.5122 - val_accuracy: 0.7939\n",
      "Epoch 6/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.3618 - accuracy: 0.8720 - val_loss: 0.5058 - val_accuracy: 0.7983\n",
      "Epoch 7/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.3497 - accuracy: 0.8836 - val_loss: 0.4958 - val_accuracy: 0.7998\n",
      "Epoch 8/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3523 - accuracy: 0.8802 - val_loss: 0.4850 - val_accuracy: 0.8079\n",
      "Epoch 9/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3538 - accuracy: 0.8843 - val_loss: 0.5073 - val_accuracy: 0.7983\n",
      "Epoch 10/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3614 - accuracy: 0.8760 - val_loss: 0.4979 - val_accuracy: 0.8026\n",
      "Epoch 11/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3471 - accuracy: 0.8772 - val_loss: 0.5019 - val_accuracy: 0.8019\n",
      "Epoch 12/12\n",
      "164/164 [==============================] - 49s 301ms/step - loss: 0.3514 - accuracy: 0.8789 - val_loss: 0.5104 - val_accuracy: 0.8013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.75802   0.92452   0.83303      3246\n",
      "           1    0.88305   0.65883   0.75464      2808\n",
      "\n",
      "    accuracy                        0.80129      6054\n",
      "   macro avg    0.82054   0.79168   0.79384      6054\n",
      "weighted avg    0.81601   0.80129   0.79667      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.13043   0.75000   0.22222         4\n",
      "           1    0.90000   0.31034   0.46154        29\n",
      "\n",
      "    accuracy                        0.36364        33\n",
      "   macro avg    0.51522   0.53017   0.34188        33\n",
      "weighted avg    0.80672   0.36364   0.43253        33\n",
      "\n",
      "Epoch 1/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.5951 - accuracy: 0.7073 - val_loss: 0.5323 - val_accuracy: 0.7770\n",
      "Epoch 2/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.4116 - accuracy: 0.8620 - val_loss: 0.5379 - val_accuracy: 0.7801\n",
      "Epoch 3/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.3778 - accuracy: 0.8661 - val_loss: 0.5087 - val_accuracy: 0.7902\n",
      "Epoch 4/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3675 - accuracy: 0.8734 - val_loss: 0.5293 - val_accuracy: 0.7869\n",
      "Epoch 5/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.3627 - accuracy: 0.8728 - val_loss: 0.5083 - val_accuracy: 0.7952\n",
      "Epoch 6/12\n",
      "164/164 [==============================] - 50s 309ms/step - loss: 0.3668 - accuracy: 0.8739 - val_loss: 0.5026 - val_accuracy: 0.7990\n",
      "Epoch 7/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3588 - accuracy: 0.8777 - val_loss: 0.4968 - val_accuracy: 0.8033\n",
      "Epoch 8/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3456 - accuracy: 0.8849 - val_loss: 0.4800 - val_accuracy: 0.8082\n",
      "Epoch 9/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3652 - accuracy: 0.8749 - val_loss: 0.4962 - val_accuracy: 0.8034\n",
      "Epoch 10/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3538 - accuracy: 0.8719 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
      "Epoch 11/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3461 - accuracy: 0.8840 - val_loss: 0.5208 - val_accuracy: 0.7958\n",
      "Epoch 12/12\n",
      "164/164 [==============================] - 50s 307ms/step - loss: 0.3620 - accuracy: 0.8721 - val_loss: 0.4827 - val_accuracy: 0.8081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78548   0.88324   0.83150      3246\n",
      "           1    0.84235   0.72115   0.77705      2808\n",
      "\n",
      "    accuracy                        0.80806      6054\n",
      "   macro avg    0.81391   0.80220   0.80427      6054\n",
      "weighted avg    0.81186   0.80806   0.80624      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.15000   0.75000   0.25000         4\n",
      "           1    0.92308   0.41379   0.57143        29\n",
      "\n",
      "    accuracy                        0.45455        33\n",
      "   macro avg    0.53654   0.58190   0.41071        33\n",
      "weighted avg    0.82937   0.45455   0.53247        33\n",
      "\n",
      "Epoch 1/12\n",
      "164/164 [==============================] - 51s 307ms/step - loss: 0.6327 - accuracy: 0.6690 - val_loss: 0.5578 - val_accuracy: 0.7714\n",
      "Epoch 2/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.4240 - accuracy: 0.8565 - val_loss: 0.5461 - val_accuracy: 0.7783\n",
      "Epoch 3/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3811 - accuracy: 0.8751 - val_loss: 0.5419 - val_accuracy: 0.7843\n",
      "Epoch 4/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3706 - accuracy: 0.8765 - val_loss: 0.5044 - val_accuracy: 0.7953\n",
      "Epoch 5/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3671 - accuracy: 0.8734 - val_loss: 0.5240 - val_accuracy: 0.7901\n",
      "Epoch 6/12\n",
      "164/164 [==============================] - 50s 307ms/step - loss: 0.3658 - accuracy: 0.8672 - val_loss: 0.4996 - val_accuracy: 0.7996\n",
      "Epoch 7/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.3579 - accuracy: 0.8809 - val_loss: 0.4976 - val_accuracy: 0.8023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3567 - accuracy: 0.8784 - val_loss: 0.5156 - val_accuracy: 0.7980\n",
      "Epoch 9/12\n",
      "164/164 [==============================] - 50s 304ms/step - loss: 0.3513 - accuracy: 0.8776 - val_loss: 0.4964 - val_accuracy: 0.8028\n",
      "Epoch 10/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3546 - accuracy: 0.8757 - val_loss: 0.5258 - val_accuracy: 0.7947\n",
      "Epoch 11/12\n",
      "164/164 [==============================] - 50s 305ms/step - loss: 0.3529 - accuracy: 0.8792 - val_loss: 0.5228 - val_accuracy: 0.7962\n",
      "Epoch 12/12\n",
      "164/164 [==============================] - 49s 302ms/step - loss: 0.3593 - accuracy: 0.8762 - val_loss: 0.4994 - val_accuracy: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76987   0.90696   0.83281      3246\n",
      "           1    0.86457   0.68661   0.76538      2808\n",
      "\n",
      "    accuracy                        0.80476      6054\n",
      "   macro avg    0.81722   0.79679   0.79910      6054\n",
      "weighted avg    0.81380   0.80476   0.80154      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.13043   0.75000   0.22222         4\n",
      "           1    0.90000   0.31034   0.46154        29\n",
      "\n",
      "    accuracy                        0.36364        33\n",
      "   macro avg    0.51522   0.53017   0.34188        33\n",
      "weighted avg    0.80672   0.36364   0.43253        33\n",
      "\n",
      "Epoch 1/12\n",
      "164/164 [==============================] - 51s 308ms/step - loss: 0.6246 - accuracy: 0.6858 - val_loss: 0.5607 - val_accuracy: 0.7643\n",
      "Epoch 2/12\n",
      "164/164 [==============================] - 51s 311ms/step - loss: 0.4317 - accuracy: 0.8500 - val_loss: 0.5083 - val_accuracy: 0.7901\n",
      "Epoch 3/12\n",
      "164/164 [==============================] - 50s 307ms/step - loss: 0.3973 - accuracy: 0.8596 - val_loss: 0.5024 - val_accuracy: 0.7944\n",
      "Epoch 4/12\n",
      "164/164 [==============================] - 50s 309ms/step - loss: 0.3638 - accuracy: 0.8750 - val_loss: 0.5027 - val_accuracy: 0.7948\n",
      "Epoch 5/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.3653 - accuracy: 0.8725 - val_loss: 0.5063 - val_accuracy: 0.7968\n",
      "Epoch 6/12\n",
      "164/164 [==============================] - 51s 312ms/step - loss: 0.3612 - accuracy: 0.8750 - val_loss: 0.5281 - val_accuracy: 0.7902\n",
      "Epoch 7/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.3610 - accuracy: 0.8823 - val_loss: 0.5309 - val_accuracy: 0.7906\n",
      "Epoch 8/12\n",
      "164/164 [==============================] - 51s 312ms/step - loss: 0.3528 - accuracy: 0.8818 - val_loss: 0.5303 - val_accuracy: 0.7932\n",
      "Epoch 9/12\n",
      "164/164 [==============================] - 50s 306ms/step - loss: 0.3520 - accuracy: 0.8806 - val_loss: 0.4819 - val_accuracy: 0.8109\n",
      "Epoch 10/12\n",
      "164/164 [==============================] - 50s 309ms/step - loss: 0.3460 - accuracy: 0.8855 - val_loss: 0.5037 - val_accuracy: 0.8028\n",
      "Epoch 11/12\n",
      "164/164 [==============================] - 51s 310ms/step - loss: 0.3482 - accuracy: 0.8765 - val_loss: 0.5078 - val_accuracy: 0.8013\n",
      "Epoch 12/12\n",
      "164/164 [==============================] - 50s 308ms/step - loss: 0.3493 - accuracy: 0.8810 - val_loss: 0.5135 - val_accuracy: 0.7990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.75420   0.92730   0.83184      3246\n",
      "           1    0.88560   0.65064   0.75015      2808\n",
      "\n",
      "    accuracy                        0.79898      6054\n",
      "   macro avg    0.81990   0.78897   0.79100      6054\n",
      "weighted avg    0.81515   0.79898   0.79395      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.13043   0.75000   0.22222         4\n",
      "           1    0.90000   0.31034   0.46154        29\n",
      "\n",
      "    accuracy                        0.36364        33\n",
      "   macro avg    0.51522   0.53017   0.34188        33\n",
      "weighted avg    0.80672   0.36364   0.43253        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amyt = np.argmax(y_t, axis=-1)\n",
    "amytp = np.argmax(yt_p, axis=-1)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    def_model = model_fn('utk', 'small')\n",
    "    def_model.fit(def_trn_x, def_trn_y, epochs=12, batch_size=32, validation_data=(x_t, y_t))\n",
    "    \n",
    "    ampt = np.argmax(def_model.predict(x_t), axis=-1)\n",
    "    amptp = np.argmax(def_model.predict(xt_p), axis=-1)\n",
    "    \n",
    "    print(classification_report(amyt, ampt, digits=5))\n",
    "    print(classification_report(amytp, amptp, digits=5)) \n",
    "\n",
    "    pacc = classification_report(amytp, amptp, digits=5, output_dict=True)['accuracy']    \n",
    "    accs.append(pacc)\n",
    "    \n",
    "    del def_model, ampt, amptp\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36363636363636365,\n",
       " 0.36363636363636365,\n",
       " 0.45454545454545453,\n",
       " 0.36363636363636365,\n",
       " 0.36363636363636365]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38181818181818183"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
