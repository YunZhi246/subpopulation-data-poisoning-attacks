{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_nlp import init_cluster_attack\n",
    "\n",
    "from subclass_avail import common\n",
    "from subclass_avail.target_nlp import bert_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transfer.top_target_training\n",
    "def model_fn(dataset, size):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    if dataset=='cifar':\n",
    "        shape = (32, 32, 3)\n",
    "        n_classes = 10\n",
    "        if size=='small':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            scales = 3\n",
    "            reg = tf.keras.regularizers.l2(l=0.00)\n",
    "            model.add(tf.keras.layers.InputLayer(shape))\n",
    "            model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "            for scale in range(scales):\n",
    "                model.add(tf.keras.layers.Conv2D(32 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.Conv2D(64 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.AveragePooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.Conv2D(n_classes, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "            #model.add(tf.keras.layers.Lambda(lambda x: tf.math.reduce_mean(x, axis=[1, 2])))\n",
    "            #model.add(tf.keras.layers.Softmax())\n",
    "            \n",
    "            opt = tf.keras.optimizers.Adam(lr=0.001)  # SGD(0.002, momentum=.5)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "            return model\n",
    "    else:\n",
    "        shape = (100, 100, 3)\n",
    "        n_classes = 2\n",
    "    vgg = tf.keras.applications.VGG16(include_top=False, input_shape=shape, pooling='avg')\n",
    "    if size=='small':\n",
    "        opt = tf.keras.optimizers.Adam(0.001)\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.Adam(0.0001)  # SGD(0.01, momentum=.9)\n",
    "\n",
    "    output = tf.keras.layers.Dense(n_classes, kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            activation='softmax')(vgg.output)\n",
    "    model = tf.keras.models.Model(inputs=vgg.inputs[0], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/net/data/malware-backdoor/subpop/victim_models/utk_small'\n",
    "\n",
    "n_clus = 100\n",
    "seed = 42\n",
    "\n",
    "pois_rate = 1\n",
    "size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_pop = 58\n",
    "cl_ind = victim_pop\n",
    "\n",
    "pth = os.path.join(results_dir, 'clind58_rate1')\n",
    "\n",
    "pois_x = np.load(os.path.join(pth, 'pois_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_y = np.load(os.path.join(pth, 'pois_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "trn_x = np.load(os.path.join(pth, 'trn_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_y = np.load(os.path.join(pth, 'trn_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_t = np.load(os.path.join(pth, 'x_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_t = np.load(os.path.join(pth, 'y_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "xt_p = np.load(os.path.join(pth, 'xt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "yt_p = np.load(os.path.join(pth, 'yt_p_{}.npy'.format(cl_ind)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(trn_y[-pois_y.shape[0]:], pois_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y_int = np.argmax(trn_y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_idx = np.zeros_like(trn_y_int)\n",
    "poison_idx[-pois_y.shape[0]:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(poison_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pois_idx0 = poison_idx[trn_y_int == 0]\n",
    "pois_idx1 = poison_idx[trn_y_int == 1]\n",
    "print(sum(pois_idx0))\n",
    "print(sum(pois_idx1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attacked model\n",
    "\n",
    "We can now load the attacked model for the selected subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading victim model for subpopulation 58\n"
     ]
    }
   ],
   "source": [
    "print('Loading victim model for subpopulation {}'.format(victim_pop))\n",
    "\n",
    "victim_model_path = os.path.join(pth, 'victim_vgg_{}'.format(victim_pop))\n",
    "victim_model = tf.keras.models.load_model(victim_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = victim_model.predict(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81636   0.90388   0.85789      3246\n",
      "           1    0.87317   0.76496   0.81549      2808\n",
      "\n",
      "    accuracy                        0.83944      6054\n",
      "   macro avg    0.84477   0.83442   0.83669      6054\n",
      "weighted avg    0.84271   0.83944   0.83823      6054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_t, axis=-1), np.argmax(pred, axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14815   1.00000   0.25806         4\n",
      "           1    1.00000   0.20690   0.34286        29\n",
      "\n",
      "    accuracy                        0.30303        33\n",
      "   macro avg    0.57407   0.60345   0.30046        33\n",
      "weighted avg    0.89675   0.30303   0.33258        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(yt_p, axis=-1), np.argmax(victim_model.predict(xt_p), axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = len(victim_model.layers) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20054, 100, 100, 3)\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19]), array([2539, 2325, 1907, 1811, 1997, 1493,  494,  345, 1382,  642,  157,\n",
      "        281, 1594,  913,  692,  233,  774,  344,  113,   18]))\n",
      "(7000, 100, 100, 3) (7000, 512) (7000, 2)\n"
     ]
    }
   ],
   "source": [
    "PCA_DIM = 2000\n",
    "C = 0.0001\n",
    "img_pp = np.load('data/utk_imgs.npy')\n",
    "fea_pp = np.load('data/utk_preds.npy')\n",
    "cl_pp = np.load('data/utk_classes.npy')\n",
    "include_inds = np.where(cl_pp[:, 0] >= 15)[0]\n",
    "fea = fea_pp[include_inds]\n",
    "cl = cl_pp[include_inds]\n",
    "img = img_pp[include_inds]\n",
    "print(img.shape)\n",
    "target = np.eye(2)[cl[:, 1]]  # 0 == age, 1 == gender, 2 == race\n",
    "age_buckets = [30, 45, 60]\n",
    "ages = np.array([cl[:, 0] >= b for b in age_buckets]).sum(axis=0)\n",
    "races = cl[:, 2]\n",
    "target_name = races*4 + ages\n",
    "print(np.unique(target_name, return_counts=True))\n",
    "trn_size = 7000\n",
    "aux_size = 7000\n",
    "tst_size = fea.shape[0] - trn_size - aux_size\n",
    "np.random.seed(0)\n",
    "inds_shuffle = np.random.choice(fea.shape[0], fea.shape[0])\n",
    "trn_inds = inds_shuffle[:trn_size]\n",
    "aux_inds = inds_shuffle[trn_size:trn_size + aux_size]\n",
    "tst_inds = inds_shuffle[trn_size + aux_size:]\n",
    "\n",
    "fea_trn, targ_trn, tn_trn = fea[trn_inds], target[trn_inds], target_name[trn_inds]\n",
    "fea_aux, targ_aux, tn_aux = fea[aux_inds], target[aux_inds], target_name[aux_inds]\n",
    "fea_tst, targ_tst, tn_tst = fea[tst_inds], target[tst_inds], target_name[tst_inds]\n",
    "\n",
    "img_trn, img_aux, img_tst = img[trn_inds], img[aux_inds], img[tst_inds]\n",
    "print(img_trn.shape, fea_trn.shape, targ_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25294"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del victim_model\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "219/219 [==============================] - 32s 143ms/step - loss: 0.6735 - accuracy: 0.6567\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 32s 144ms/step - loss: 0.4827 - accuracy: 0.8181\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 32s 144ms/step - loss: 0.4512 - accuracy: 0.8287\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4405 - accuracy: 0.8382\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4290 - accuracy: 0.8398\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 31s 144ms/step - loss: 0.4296 - accuracy: 0.8385\n",
      "Epoch 7/12\n",
      "219/219 [==============================] - 31s 144ms/step - loss: 0.4238 - accuracy: 0.8418\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4203 - accuracy: 0.8515\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4219 - accuracy: 0.8498\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4142 - accuracy: 0.8549\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4133 - accuracy: 0.8505\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4276 - accuracy: 0.8384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82243   0.89464   0.85702      3246\n",
      "           1    0.86445   0.77671   0.81823      2808\n",
      "\n",
      "    accuracy                        0.83994      6054\n",
      "   macro avg    0.84344   0.83567   0.83762      6054\n",
      "weighted avg    0.84192   0.83994   0.83903      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.15000   0.75000   0.25000         4\n",
      "           1    0.92308   0.41379   0.57143        29\n",
      "\n",
      "    accuracy                        0.45455        33\n",
      "   macro avg    0.53654   0.58190   0.41071        33\n",
      "weighted avg    0.82937   0.45455   0.53247        33\n",
      "\n",
      "Epoch 1/12\n",
      "219/219 [==============================] - 32s 142ms/step - loss: 0.6346 - accuracy: 0.7063\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4719 - accuracy: 0.8304\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 31s 144ms/step - loss: 0.4432 - accuracy: 0.8375\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4406 - accuracy: 0.8389\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 32s 145ms/step - loss: 0.4263 - accuracy: 0.8406\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4225 - accuracy: 0.8468\n",
      "Epoch 7/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4302 - accuracy: 0.8445\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4109 - accuracy: 0.8493\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 32s 144ms/step - loss: 0.4280 - accuracy: 0.8435\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4248 - accuracy: 0.8365\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4196 - accuracy: 0.8485\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 32s 145ms/step - loss: 0.4157 - accuracy: 0.8470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82051   0.89710   0.85710      3246\n",
      "           1    0.86667   0.77315   0.81724      2808\n",
      "\n",
      "    accuracy                        0.83961      6054\n",
      "   macro avg    0.84359   0.83513   0.83717      6054\n",
      "weighted avg    0.84192   0.83961   0.83861      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.15789   0.75000   0.26087         4\n",
      "           1    0.92857   0.44828   0.60465        29\n",
      "\n",
      "    accuracy                        0.48485        33\n",
      "   macro avg    0.54323   0.59914   0.43276        33\n",
      "weighted avg    0.83516   0.48485   0.56298        33\n",
      "\n",
      "Epoch 1/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.6707 - accuracy: 0.6413\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4777 - accuracy: 0.8208\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 31s 140ms/step - loss: 0.4465 - accuracy: 0.8313\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4387 - accuracy: 0.8334\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 31s 140ms/step - loss: 0.4233 - accuracy: 0.8516\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 31s 139ms/step - loss: 0.4168 - accuracy: 0.8478\n",
      "Epoch 7/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4260 - accuracy: 0.8405\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 31s 140ms/step - loss: 0.4174 - accuracy: 0.8501\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 31s 140ms/step - loss: 0.4181 - accuracy: 0.8496\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4229 - accuracy: 0.8468\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4082 - accuracy: 0.8537\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 31s 140ms/step - loss: 0.4302 - accuracy: 0.8431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81421   0.90727   0.85823      3246\n",
      "           1    0.87649   0.76068   0.81449      2808\n",
      "\n",
      "    accuracy                        0.83928      6054\n",
      "   macro avg    0.84535   0.83398   0.83636      6054\n",
      "weighted avg    0.84310   0.83928   0.83794      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.16667   0.75000   0.27273         4\n",
      "           1    0.93333   0.48276   0.63636        29\n",
      "\n",
      "    accuracy                        0.51515        33\n",
      "   macro avg    0.55000   0.61638   0.45455        33\n",
      "weighted avg    0.84040   0.51515   0.59229        33\n",
      "\n",
      "Epoch 1/12\n",
      "219/219 [==============================] - 32s 143ms/step - loss: 0.6261 - accuracy: 0.7074\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4669 - accuracy: 0.8269\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4478 - accuracy: 0.8282\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4323 - accuracy: 0.8433\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4328 - accuracy: 0.8421\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4268 - accuracy: 0.8452\n",
      "Epoch 7/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4245 - accuracy: 0.8460\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 31s 144ms/step - loss: 0.4219 - accuracy: 0.8416\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4156 - accuracy: 0.8445\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4225 - accuracy: 0.8481\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 32s 145ms/step - loss: 0.4239 - accuracy: 0.8426\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4129 - accuracy: 0.8510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85224   0.85644   0.85433      3246\n",
      "           1    0.83309   0.82835   0.83071      2808\n",
      "\n",
      "    accuracy                        0.84341      6054\n",
      "   macro avg    0.84267   0.84239   0.84252      6054\n",
      "weighted avg    0.84336   0.84341   0.84338      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.25000   0.75000   0.37500         4\n",
      "           1    0.95238   0.68966   0.80000        29\n",
      "\n",
      "    accuracy                        0.69697        33\n",
      "   macro avg    0.60119   0.71983   0.58750        33\n",
      "weighted avg    0.86724   0.69697   0.74848        33\n",
      "\n",
      "Epoch 1/12\n",
      "219/219 [==============================] - 32s 142ms/step - loss: 0.6410 - accuracy: 0.6745\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4709 - accuracy: 0.8201\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4449 - accuracy: 0.8356\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4328 - accuracy: 0.8439\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 31s 144ms/step - loss: 0.4221 - accuracy: 0.8429\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4233 - accuracy: 0.8456\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4229 - accuracy: 0.8439\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 31s 141ms/step - loss: 0.4195 - accuracy: 0.8445\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4220 - accuracy: 0.8441\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4138 - accuracy: 0.8557\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 31s 143ms/step - loss: 0.4149 - accuracy: 0.8511\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.4180 - accuracy: 0.8466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84803   0.86815   0.85797      3246\n",
      "           1    0.84328   0.82016   0.83156      2808\n",
      "\n",
      "    accuracy                        0.84589      6054\n",
      "   macro avg    0.84565   0.84415   0.84476      6054\n",
      "weighted avg    0.84583   0.84589   0.84572      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.25000   0.75000   0.37500         4\n",
      "           1    0.95238   0.68966   0.80000        29\n",
      "\n",
      "    accuracy                        0.69697        33\n",
      "   macro avg    0.60119   0.71983   0.58750        33\n",
      "weighted avg    0.86724   0.69697   0.74848        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "amyt = np.argmax(y_t, axis=-1)\n",
    "amytp = np.argmax(yt_p, axis=-1)\n",
    "\n",
    "for i in range(5):\n",
    "    def_model = model_fn('utk', 'small')\n",
    "    def_model.fit(img_trn, targ_trn, epochs=12, batch_size=32)\n",
    "    \n",
    "    ampt = np.argmax(def_model.predict(x_t), axis=-1)\n",
    "    amptp = np.argmax(def_model.predict(xt_p), axis=-1)\n",
    "    \n",
    "    print(classification_report(amyt, ampt, digits=5))\n",
    "    print(classification_report(amytp, amptp, digits=5))\n",
    "\n",
    "    pacc = classification\n",
    "    _report(amytp, amptp, digits=5, output_dict=True)['accuracy']    \n",
    "    accs.append(pacc)\n",
    "    \n",
    "    del def_model, ampt, amptp\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45454545454545453,\n",
       " 0.48484848484848486,\n",
       " 0.5151515151515151,\n",
       " 0.696969696969697,\n",
       " 0.696969696969697]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
