{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral signatures defense\n",
    "\n",
    "In this notebook we will evaluate the effect of filtering using spectral signatures https://papers.nips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf\n",
    "\n",
    "Some code adapted from https://github.com/MadryLab/backdoor_data_poisoning/blob/master/compute_corr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_nlp import init_cluster_attack\n",
    "\n",
    "from subclass_avail import common\n",
    "from subclass_avail.target_nlp import bert_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transfer.top_target_training\n",
    "def model_fn(dataset, size):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    if dataset=='cifar':\n",
    "        shape = (32, 32, 3)\n",
    "        n_classes = 10\n",
    "        if size=='small':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            scales = 3\n",
    "            reg = tf.keras.regularizers.l2(l=0.00)\n",
    "            model.add(tf.keras.layers.InputLayer(shape))\n",
    "            model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "            for scale in range(scales):\n",
    "                model.add(tf.keras.layers.Conv2D(32 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.Conv2D(64 << scale, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "                model.add(tf.keras.layers.AveragePooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.Conv2D(n_classes, (3, 3), padding='same',\n",
    "                    kernel_regularizer=reg))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "            #model.add(tf.keras.layers.Lambda(lambda x: tf.math.reduce_mean(x, axis=[1, 2])))\n",
    "            #model.add(tf.keras.layers.Softmax())\n",
    "            \n",
    "            opt = tf.keras.optimizers.Adam(lr=0.001)  # SGD(0.002, momentum=.5)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "            return model\n",
    "    else:\n",
    "        shape = (100, 100, 3)\n",
    "        n_classes = 2\n",
    "    vgg = tf.keras.applications.VGG16(include_top=False, input_shape=shape, pooling='avg')\n",
    "    if size=='small':\n",
    "        opt = tf.keras.optimizers.Adam(0.001)\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.Adam(0.0001)  # SGD(0.01, momentum=.9)\n",
    "\n",
    "    output = tf.keras.layers.Dense(n_classes, kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            activation='softmax')(vgg.output)\n",
    "    model = tf.keras.models.Model(inputs=vgg.inputs[0], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/net/data/malware-backdoor/subpop/victim_models/utk_small'\n",
    "\n",
    "n_clus = 100\n",
    "seed = 42\n",
    "\n",
    "pois_rate = 1\n",
    "size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_pop = 58\n",
    "cl_ind = victim_pop\n",
    "\n",
    "pth = os.path.join(results_dir, 'clind58_rate1')\n",
    "\n",
    "pois_x = np.load(os.path.join(pth, 'pois_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "pois_y = np.load(os.path.join(pth, 'pois_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "trn_x = np.load(os.path.join(pth, 'trn_x_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "trn_y = np.load(os.path.join(pth, 'trn_y_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "x_t = np.load(os.path.join(pth, 'x_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "y_t = np.load(os.path.join(pth, 'y_t_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "\n",
    "xt_p = np.load(os.path.join(pth, 'xt_p_{}.npy'.format(cl_ind)), allow_pickle=True)\n",
    "yt_p = np.load(os.path.join(pth, 'yt_p_{}.npy'.format(cl_ind)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(trn_y[-pois_y.shape[0]:], pois_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y_int = np.argmax(trn_y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_idx = np.zeros_like(trn_y_int)\n",
    "poison_idx[-pois_y.shape[0]:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(poison_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pois_idx0 = poison_idx[trn_y_int == 0]\n",
    "pois_idx1 = poison_idx[trn_y_int == 1]\n",
    "print(sum(pois_idx0))\n",
    "print(sum(pois_idx1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attacked model\n",
    "\n",
    "We can now load the attacked model for the selected subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading victim model for subpopulation 58\n"
     ]
    }
   ],
   "source": [
    "print('Loading victim model for subpopulation {}'.format(victim_pop))\n",
    "\n",
    "victim_model_path = os.path.join(pth, 'victim_vgg_{}'.format(victim_pop))\n",
    "victim_model = tf.keras.models.load_model(victim_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = victim_model.predict(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81636   0.90388   0.85789      3246\n",
      "           1    0.87317   0.76496   0.81549      2808\n",
      "\n",
      "    accuracy                        0.83944      6054\n",
      "   macro avg    0.84477   0.83442   0.83669      6054\n",
      "weighted avg    0.84271   0.83944   0.83823      6054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_t, axis=-1), np.argmax(pred, axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14815   1.00000   0.25806         4\n",
      "           1    1.00000   0.20690   0.34286        29\n",
      "\n",
      "    accuracy                        0.30303        33\n",
      "   macro avg    0.57407   0.60345   0.30046        33\n",
      "weighted avg    0.89675   0.30303   0.33258        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(yt_p, axis=-1), np.argmax(victim_model.predict(xt_p), axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = len(victim_model.layers) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.03899719 0.20827405 0.01483871]\n",
      " [0.26167235 0.         0.05851512 ... 0.09421486 0.2721647  0.        ]\n",
      " [0.02343429 0.         0.         ... 0.3397394  0.37460688 0.00310088]\n",
      " ...\n",
      " [0.555617   0.02917427 0.03418446 ... 0.30539954 0.5587245  0.        ]\n",
      " [0.         0.         0.         ... 0.13902754 0.19241796 0.        ]\n",
      " [0.         0.         0.         ... 0.6099808  0.2267428  0.00134307]]\n"
     ]
    }
   ],
   "source": [
    "layerout = K.function([victim_model.get_layer(index=0).input], victim_model.get_layer(index=last_layer).output)\n",
    "repres_trn = layerout([trn_x])\n",
    "print(repres_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del victim_model\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7040, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repres_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\n",
      "corrs shape (1, 3748)\n",
      "scores shape (3748,)\n",
      "score percentile shape ()\n",
      "score percentile 2.564788734912871\n",
      "top scores shape (563,)\n",
      "to remove shape (3748,)\n",
      "to remove sum 563.0\n",
      "CLASS 1\n",
      "corrs shape (1, 3292)\n",
      "scores shape (3292,)\n",
      "score percentile shape ()\n",
      "score percentile 1.9886060893535613\n",
      "top scores shape (494,)\n",
      "to remove shape (3292,)\n",
      "to remove sum 494.0\n"
     ]
    }
   ],
   "source": [
    "remove_lists = []\n",
    "\n",
    "for cls in classes:\n",
    "    print('CLASS', cls)\n",
    "    \n",
    "    repres = repres_trn[trn_y_int == cls]\n",
    "    repres = repres.reshape(repres.shape[0], -1)\n",
    "    r_hat = np.mean(repres, axis=0)\n",
    "    m_centered = repres - r_hat\n",
    "    \n",
    "    u, s, v = np.linalg.svd(m_centered, full_matrices=False)\n",
    "    \n",
    "    eigs = v[0:1]\n",
    "    corrs = np.matmul(eigs, np.transpose(m_centered))  # shape num_top, num_active_indices\n",
    "\n",
    "    print('corrs shape', corrs.shape)\n",
    "    scores = np.linalg.norm(corrs, axis=0)  # shape num_active_indices\n",
    "    print('scores shape', scores.shape)\n",
    "\n",
    "    score_percentile = np.percentile(scores, 85)  # Discard top 15%\n",
    "    print('score percentile shape', score_percentile.shape)\n",
    "    print('score percentile', score_percentile)\n",
    "\n",
    "    top_scores = np.where(scores > score_percentile)[0]\n",
    "    print('top scores shape', top_scores.shape)\n",
    "\n",
    "    # make bitmap with samples to remove\n",
    "    to_remove = np.zeros(shape=repres.shape[0])\n",
    "    to_remove[top_scores] = 1\n",
    "    print('to remove shape', to_remove.shape)\n",
    "    print('to remove sum', sum(to_remove))\n",
    "    remove_lists.append(to_remove)\n",
    "    \n",
    "    del r_hat, m_centered, u, s, v, corrs, scores, score_percentile, top_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "rl0 = remove_lists[0]\n",
    "rl1 = remove_lists[1]\n",
    "\n",
    "for i in range(len(rl0)):\n",
    "    if rl0[i] == 1 and pois_idx0[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "for i in range(len(rl1)):\n",
    "    if rl1[i] == 1 and pois_idx1[i] == 1:\n",
    "        found +=1\n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3748, 100, 100, 3) (3748, 2) (3292, 100, 100, 3) (3292, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = np.copy(trn_x[trn_y_int == 0])\n",
    "def_trn_y0 = np.copy(trn_y[trn_y_int == 0])\n",
    "def_trn_x1 = np.copy(trn_x[trn_y_int == 1])\n",
    "def_trn_y1 = np.copy(trn_y[trn_y_int == 1])\n",
    "print(def_trn_x0.shape, def_trn_y0.shape, def_trn_x1.shape, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3185, 100, 100, 3) (3185, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x0 = def_trn_x0[~remove_lists[0].astype(bool)]\n",
    "def_trn_y0 = def_trn_y0[~remove_lists[0].astype(bool)]\n",
    "print(def_trn_x0.shape, def_trn_y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 100, 100, 3) (2798, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x1 = def_trn_x1[~remove_lists[1].astype(bool)]\n",
    "def_trn_y1 = def_trn_y1[~remove_lists[1].astype(bool)]\n",
    "print(def_trn_x1.shape, def_trn_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5983, 100, 100, 3) (5983, 2)\n"
     ]
    }
   ],
   "source": [
    "def_trn_x = np.concatenate([def_trn_x0, def_trn_x1])\n",
    "def_trn_y = np.concatenate([def_trn_y0, def_trn_y1])\n",
    "print(def_trn_x.shape, def_trn_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5983,)\n"
     ]
    }
   ],
   "source": [
    "shuffle_idx = np.random.choice(def_trn_x.shape[0], def_trn_x.shape[0], replace=False)\n",
    "print(shuffle_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_trn_x = def_trn_x[shuffle_idx]\n",
    "def_trn_y = def_trn_y[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "187/187 [==============================] - 102s 541ms/step - loss: 0.6703 - accuracy: 0.6290 - val_loss: 0.5198 - val_accuracy: 0.7950\n",
      "Epoch 2/12\n",
      "187/187 [==============================] - 96s 515ms/step - loss: 0.4752 - accuracy: 0.8244 - val_loss: 0.4724 - val_accuracy: 0.8095\n",
      "Epoch 3/12\n",
      "187/187 [==============================] - 102s 546ms/step - loss: 0.4312 - accuracy: 0.8425 - val_loss: 0.4610 - val_accuracy: 0.8185\n",
      "Epoch 4/12\n",
      "187/187 [==============================] - 105s 565ms/step - loss: 0.4121 - accuracy: 0.8526 - val_loss: 0.4520 - val_accuracy: 0.8190\n",
      "Epoch 5/12\n",
      "187/187 [==============================] - 122s 652ms/step - loss: 0.4118 - accuracy: 0.8427 - val_loss: 0.4482 - val_accuracy: 0.8241\n",
      "Epoch 6/12\n",
      "187/187 [==============================] - 132s 706ms/step - loss: 0.3944 - accuracy: 0.8541 - val_loss: 0.4453 - val_accuracy: 0.8223\n",
      "Epoch 7/12\n",
      "187/187 [==============================] - 131s 701ms/step - loss: 0.4042 - accuracy: 0.8544 - val_loss: 0.4476 - val_accuracy: 0.8256\n",
      "Epoch 8/12\n",
      "187/187 [==============================] - 141s 756ms/step - loss: 0.3964 - accuracy: 0.8537 - val_loss: 0.4478 - val_accuracy: 0.8261\n",
      "Epoch 9/12\n",
      "187/187 [==============================] - 105s 563ms/step - loss: 0.3983 - accuracy: 0.8555 - val_loss: 0.4534 - val_accuracy: 0.8224\n",
      "Epoch 10/12\n",
      "187/187 [==============================] - 105s 563ms/step - loss: 0.4108 - accuracy: 0.8504 - val_loss: 0.4410 - val_accuracy: 0.8276\n",
      "Epoch 11/12\n",
      "187/187 [==============================] - 96s 514ms/step - loss: 0.3910 - accuracy: 0.8610 - val_loss: 0.4450 - val_accuracy: 0.8280\n",
      "Epoch 12/12\n",
      "187/187 [==============================] - 79s 425ms/step - loss: 0.4139 - accuracy: 0.8462 - val_loss: 0.4408 - val_accuracy: 0.8282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81916   0.87215   0.84482      3246\n",
      "           1    0.84026   0.77742   0.80762      2808\n",
      "\n",
      "    accuracy                        0.82821      6054\n",
      "   macro avg    0.82971   0.82479   0.82622      6054\n",
      "weighted avg    0.82894   0.82821   0.82757      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14286   1.00000   0.25000         4\n",
      "           1    1.00000   0.17241   0.29412        29\n",
      "\n",
      "    accuracy                        0.27273        33\n",
      "   macro avg    0.57143   0.58621   0.27206        33\n",
      "weighted avg    0.89610   0.27273   0.28877        33\n",
      "\n",
      "Epoch 1/12\n",
      "187/187 [==============================] - 98s 520ms/step - loss: 0.7120 - accuracy: 0.6382 - val_loss: 0.5231 - val_accuracy: 0.7912\n",
      "Epoch 2/12\n",
      "187/187 [==============================] - 81s 435ms/step - loss: 0.4744 - accuracy: 0.8173 - val_loss: 0.4809 - val_accuracy: 0.8092\n",
      "Epoch 3/12\n",
      "187/187 [==============================] - 80s 430ms/step - loss: 0.4332 - accuracy: 0.8334 - val_loss: 0.4611 - val_accuracy: 0.8167\n",
      "Epoch 4/12\n",
      "187/187 [==============================] - 78s 419ms/step - loss: 0.4307 - accuracy: 0.8378 - val_loss: 0.4584 - val_accuracy: 0.8185\n",
      "Epoch 5/12\n",
      "187/187 [==============================] - 63s 336ms/step - loss: 0.4107 - accuracy: 0.8553 - val_loss: 0.4559 - val_accuracy: 0.8203\n",
      "Epoch 6/12\n",
      "187/187 [==============================] - 111s 596ms/step - loss: 0.4116 - accuracy: 0.8440 - val_loss: 0.4489 - val_accuracy: 0.8234\n",
      "Epoch 7/12\n",
      "187/187 [==============================] - 136s 730ms/step - loss: 0.4108 - accuracy: 0.8462 - val_loss: 0.4449 - val_accuracy: 0.8256\n",
      "Epoch 8/12\n",
      "187/187 [==============================] - 162s 868ms/step - loss: 0.4095 - accuracy: 0.8499 - val_loss: 0.4467 - val_accuracy: 0.8246\n",
      "Epoch 9/12\n",
      "187/187 [==============================] - 163s 872ms/step - loss: 0.3975 - accuracy: 0.8547 - val_loss: 0.4401 - val_accuracy: 0.8262\n",
      "Epoch 10/12\n",
      "187/187 [==============================] - 131s 700ms/step - loss: 0.4011 - accuracy: 0.8603 - val_loss: 0.4431 - val_accuracy: 0.8284\n",
      "Epoch 11/12\n",
      "187/187 [==============================] - 97s 521ms/step - loss: 0.4056 - accuracy: 0.8562 - val_loss: 0.4451 - val_accuracy: 0.8262\n",
      "Epoch 12/12\n",
      "187/187 [==============================] - 60s 320ms/step - loss: 0.4046 - accuracy: 0.8514 - val_loss: 0.4483 - val_accuracy: 0.8257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80439   0.89187   0.84587      3246\n",
      "           1    0.85703   0.74929   0.79954      2808\n",
      "\n",
      "    accuracy                        0.82574      6054\n",
      "   macro avg    0.83071   0.82058   0.82271      6054\n",
      "weighted avg    0.82880   0.82574   0.82438      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14286   1.00000   0.25000         4\n",
      "           1    1.00000   0.17241   0.29412        29\n",
      "\n",
      "    accuracy                        0.27273        33\n",
      "   macro avg    0.57143   0.58621   0.27206        33\n",
      "weighted avg    0.89610   0.27273   0.28877        33\n",
      "\n",
      "Epoch 1/12\n",
      "187/187 [==============================] - 66s 353ms/step - loss: 0.6213 - accuracy: 0.7006 - val_loss: 0.5051 - val_accuracy: 0.7919\n",
      "Epoch 2/12\n",
      "187/187 [==============================] - 89s 477ms/step - loss: 0.4587 - accuracy: 0.8335 - val_loss: 0.4715 - val_accuracy: 0.8092\n",
      "Epoch 3/12\n",
      "187/187 [==============================] - 102s 545ms/step - loss: 0.4288 - accuracy: 0.8427 - val_loss: 0.4638 - val_accuracy: 0.8107\n",
      "Epoch 4/12\n",
      "187/187 [==============================] - 123s 661ms/step - loss: 0.4167 - accuracy: 0.8434 - val_loss: 0.4533 - val_accuracy: 0.8150\n",
      "Epoch 5/12\n",
      "187/187 [==============================] - 123s 657ms/step - loss: 0.4068 - accuracy: 0.8517 - val_loss: 0.4512 - val_accuracy: 0.8214\n",
      "Epoch 6/12\n",
      "187/187 [==============================] - 105s 561ms/step - loss: 0.4111 - accuracy: 0.8475 - val_loss: 0.4463 - val_accuracy: 0.8200\n",
      "Epoch 7/12\n",
      "187/187 [==============================] - 80s 429ms/step - loss: 0.4065 - accuracy: 0.8456 - val_loss: 0.4521 - val_accuracy: 0.8214\n",
      "Epoch 8/12\n",
      "187/187 [==============================] - 73s 389ms/step - loss: 0.3981 - accuracy: 0.8543 - val_loss: 0.4404 - val_accuracy: 0.8259\n",
      "Epoch 9/12\n",
      "187/187 [==============================] - 62s 334ms/step - loss: 0.4033 - accuracy: 0.8527 - val_loss: 0.4484 - val_accuracy: 0.8261\n",
      "Epoch 10/12\n",
      "187/187 [==============================] - 86s 460ms/step - loss: 0.3991 - accuracy: 0.8516 - val_loss: 0.4598 - val_accuracy: 0.8203\n",
      "Epoch 11/12\n",
      "187/187 [==============================] - 122s 655ms/step - loss: 0.3879 - accuracy: 0.8622 - val_loss: 0.4449 - val_accuracy: 0.8264\n",
      "Epoch 12/12\n",
      "187/187 [==============================] - 121s 649ms/step - loss: 0.4034 - accuracy: 0.8579 - val_loss: 0.4394 - val_accuracy: 0.8277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82871   0.85551   0.84190      3246\n",
      "           1    0.82649   0.79558   0.81074      2808\n",
      "\n",
      "    accuracy                        0.82772      6054\n",
      "   macro avg    0.82760   0.82555   0.82632      6054\n",
      "weighted avg    0.82768   0.82772   0.82745      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14815   1.00000   0.25806         4\n",
      "           1    1.00000   0.20690   0.34286        29\n",
      "\n",
      "    accuracy                        0.30303        33\n",
      "   macro avg    0.57407   0.60345   0.30046        33\n",
      "weighted avg    0.89675   0.30303   0.33258        33\n",
      "\n",
      "Epoch 1/12\n",
      "187/187 [==============================] - 125s 663ms/step - loss: 0.6738 - accuracy: 0.6499 - val_loss: 0.5120 - val_accuracy: 0.7986\n",
      "Epoch 2/12\n",
      "187/187 [==============================] - 100s 535ms/step - loss: 0.4657 - accuracy: 0.8356 - val_loss: 0.4760 - val_accuracy: 0.8092\n",
      "Epoch 3/12\n",
      "187/187 [==============================] - 80s 429ms/step - loss: 0.4359 - accuracy: 0.8328 - val_loss: 0.4631 - val_accuracy: 0.8160\n",
      "Epoch 4/12\n",
      "187/187 [==============================] - 87s 465ms/step - loss: 0.4278 - accuracy: 0.8424 - val_loss: 0.4723 - val_accuracy: 0.8138\n",
      "Epoch 5/12\n",
      "187/187 [==============================] - 101s 544ms/step - loss: 0.4175 - accuracy: 0.8463 - val_loss: 0.4581 - val_accuracy: 0.8196\n",
      "Epoch 6/12\n",
      "187/187 [==============================] - 116s 620ms/step - loss: 0.4173 - accuracy: 0.8455 - val_loss: 0.4534 - val_accuracy: 0.8209\n",
      "Epoch 7/12\n",
      "187/187 [==============================] - 128s 689ms/step - loss: 0.4053 - accuracy: 0.8512 - val_loss: 0.4468 - val_accuracy: 0.8229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/12\n",
      "187/187 [==============================] - 140s 751ms/step - loss: 0.4101 - accuracy: 0.8510 - val_loss: 0.4548 - val_accuracy: 0.8224\n",
      "Epoch 9/12\n",
      "187/187 [==============================] - 122s 653ms/step - loss: 0.4116 - accuracy: 0.8428 - val_loss: 0.4434 - val_accuracy: 0.8276\n",
      "Epoch 10/12\n",
      "187/187 [==============================] - 106s 567ms/step - loss: 0.3992 - accuracy: 0.8568 - val_loss: 0.4422 - val_accuracy: 0.8257\n",
      "Epoch 11/12\n",
      "187/187 [==============================] - 100s 537ms/step - loss: 0.4129 - accuracy: 0.8477 - val_loss: 0.4470 - val_accuracy: 0.8269\n",
      "Epoch 12/12\n",
      "187/187 [==============================] - 131s 701ms/step - loss: 0.3955 - accuracy: 0.8593 - val_loss: 0.4460 - val_accuracy: 0.8277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81844   0.87215   0.84444      3246\n",
      "           1    0.84008   0.77635   0.80696      2808\n",
      "\n",
      "    accuracy                        0.82772      6054\n",
      "   macro avg    0.82926   0.82425   0.82570      6054\n",
      "weighted avg    0.82848   0.82772   0.82706      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14286   1.00000   0.25000         4\n",
      "           1    1.00000   0.17241   0.29412        29\n",
      "\n",
      "    accuracy                        0.27273        33\n",
      "   macro avg    0.57143   0.58621   0.27206        33\n",
      "weighted avg    0.89610   0.27273   0.28877        33\n",
      "\n",
      "Epoch 1/12\n",
      "187/187 [==============================] - 133s 709ms/step - loss: 0.5990 - accuracy: 0.7298 - val_loss: 0.5027 - val_accuracy: 0.7882\n",
      "Epoch 2/12\n",
      "187/187 [==============================] - 143s 766ms/step - loss: 0.4540 - accuracy: 0.8258 - val_loss: 0.4678 - val_accuracy: 0.8087\n",
      "Epoch 3/12\n",
      "187/187 [==============================] - 107s 575ms/step - loss: 0.4288 - accuracy: 0.8338 - val_loss: 0.4585 - val_accuracy: 0.8175\n",
      "Epoch 4/12\n",
      "187/187 [==============================] - 91s 487ms/step - loss: 0.4071 - accuracy: 0.8554 - val_loss: 0.4643 - val_accuracy: 0.8155\n",
      "Epoch 5/12\n",
      "187/187 [==============================] - 81s 435ms/step - loss: 0.4076 - accuracy: 0.8519 - val_loss: 0.4437 - val_accuracy: 0.8231\n",
      "Epoch 6/12\n",
      "187/187 [==============================] - 80s 431ms/step - loss: 0.4163 - accuracy: 0.8463 - val_loss: 0.4527 - val_accuracy: 0.8200\n",
      "Epoch 7/12\n",
      "187/187 [==============================] - 84s 449ms/step - loss: 0.4069 - accuracy: 0.8511 - val_loss: 0.4480 - val_accuracy: 0.8251\n",
      "Epoch 8/12\n",
      "187/187 [==============================] - 81s 434ms/step - loss: 0.4088 - accuracy: 0.8507 - val_loss: 0.4519 - val_accuracy: 0.8219\n",
      "Epoch 9/12\n",
      "187/187 [==============================] - 88s 472ms/step - loss: 0.4033 - accuracy: 0.8519 - val_loss: 0.4473 - val_accuracy: 0.8259\n",
      "Epoch 10/12\n",
      "187/187 [==============================] - 101s 544ms/step - loss: 0.4013 - accuracy: 0.8555 - val_loss: 0.4439 - val_accuracy: 0.8279\n",
      "Epoch 11/12\n",
      "187/187 [==============================] - 99s 528ms/step - loss: 0.3927 - accuracy: 0.8584 - val_loss: 0.4476 - val_accuracy: 0.8269\n",
      "Epoch 12/12\n",
      "187/187 [==============================] - 100s 537ms/step - loss: 0.3896 - accuracy: 0.8635 - val_loss: 0.4482 - val_accuracy: 0.8254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80344   0.89279   0.84576      3246\n",
      "           1    0.85779   0.74751   0.79886      2808\n",
      "\n",
      "    accuracy                        0.82540      6054\n",
      "   macro avg    0.83061   0.82015   0.82231      6054\n",
      "weighted avg    0.82865   0.82540   0.82401      6054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.14286   1.00000   0.25000         4\n",
      "           1    1.00000   0.17241   0.29412        29\n",
      "\n",
      "    accuracy                        0.27273        33\n",
      "   macro avg    0.57143   0.58621   0.27206        33\n",
      "weighted avg    0.89610   0.27273   0.28877        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amyt = np.argmax(y_t, axis=-1)\n",
    "amytp = np.argmax(yt_p, axis=-1)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    def_model = model_fn('utk', 'small')\n",
    "    def_model.fit(def_trn_x, def_trn_y, epochs=12, batch_size=32, validation_data=(x_t, y_t))\n",
    "    \n",
    "    ampt = np.argmax(def_model.predict(x_t), axis=-1)\n",
    "    amptp = np.argmax(def_model.predict(xt_p), axis=-1)\n",
    "    \n",
    "    print(classification_report(amyt, ampt, digits=5))\n",
    "    print(classification_report(amytp, amptp, digits=5)) \n",
    "\n",
    "    pacc = classification_report(amytp, amptp, digits=5, output_dict=True)['accuracy']    \n",
    "    accs.append(pacc)\n",
    "    \n",
    "    del def_model, ampt, amptp\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2727272727272727,\n",
       " 0.2727272727272727,\n",
       " 0.30303030303030304,\n",
       " 0.2727272727272727,\n",
       " 0.2727272727272727]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27878787878787875"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
